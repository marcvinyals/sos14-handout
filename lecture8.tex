% Copyright (C) 2014 by Massimo Lauria
% 
% Created   : "2014-01-07, Tuesday 17:01 (CET) Massimo Lauria"
% Time-stamp: "2014-03-03, 16:10 (CET) Massimo Lauria"
% Encoding  : UTF-8

% ---------------------------- USER DATA ------------------------------
\def\DataTitle{8. SoS lower bounds for 3-SAT and 3-XOR (part II).}
\def\DataTitleShort{Linear programming}
\def\DataDate{18 February, 2014}
\def\DataDocname{Lecture 8 --- \DataDate}
\def\DataLecturer{Massimo Lauria}
\def\DataScribe{Mohamed Abdalmoaty}
\def\DataKeywords{integer programming, linear programming,
  \Lovasz-\Schrijver, Sherali-Adams}

\def\DataAbstract{%
The whole lecture is devote to show that if a $k$-XOR formula $\phi$ requires degree $D$ refutations in Binomial Calculus (BC), then it requires degree $D/2$ Positivstellensatz Calculus refutations ($\mathsf{PC}_>$). 
%  This basically means that, when the initial equations are binomial equations, the reasoning power of  Positivstellensatz calculus is completely captured by binomial calculus. This is a very nice feature, since it is simpler to proof degree lower bounds using binomial calculus.
}


% ---------------------------- PREAMBLE -------------------------------
\documentclass[a4paper,twoside,justified]{tufte-handout}
\usepackage{soscourse} % this is a non standard package
\begin{document} 
% --------------------------- DOCUMENT --------------------------------



\begin{lemma}\label{lem:linComb}
Assume that 
\begin{equation}\label{eq:f-sum}
f = \sum_{i} \alpha_i  (t_i-t_i')
\end{equation}
where  $(t_i-t_i')$ has a BC refutation of degree $d$, then $f$ can be written as
\begin{equation*}
f = \sum_{i} \beta_i  (s_i-s_i')
\end{equation*}
where for each $i$ $(s_i-s_i')$ has a BC refutation of degree $d$  and all monomials in the terms $\{s_i,s_i'\}_i$ are in $f$.
\end{lemma}

\begin{proof}
Assume that some monomial $m$ appears in the RHS of (\ref{eq:f-sum}) but not in $f$. We show that we can prune that monomial from the sum without affecting $f$. Hence, repeating this process we end with the desired expression. To show how the pruning works consider the sum $S_m$ of all terms of the RHS of equation (\ref{eq:f-sum}) containing $m$:
\begin{equation*}
S_m = \sum_{j\in A} \alpha_j ( m-t'_j).
\end{equation*}
Wlog each $t'_j$ in the sum above is not containing $m$.
Moreover as $m$ doesn't appear in $f$ it $m$ must be canceled out, that is $\sum_{j\in A} \alpha_j = 0$. Fix $i\in A$ such that $t'_i$ is one of the $t'_j$ of the equation above.
 
 Then
\begin{equation*}
 S_m=\sum_{j\in A} \alpha_j m -\sum_{j\in A} \alpha_j t'_j\stackrel{\sum_{j\in A}\alpha_j=0}{=}\sum_{j\in A}\alpha_j t'_i - \sum_{j\in A} \alpha_j t'_j
 =\sum_{j\in A}\alpha_j (t'_i - t'_j).
\end{equation*}
Moreover $(t'_i-t'_j)$ for each $j\in A$ can be derived in BC using degree at most $d$ as by hypothesis both $(m-t'_i)$ and $(m-t'_j)$ can be derived in BC using degree at most $d$. Hence we showed how to prune $m$ from the RHS of (\ref{eq:f-sum}).
\end{proof}

\begin{corollary}\label{cor:normal-form}
If $f=0$ is deduced in degree $d$ by the equational part of $\mathsf{PC}_>$ then $f=\sum_j \alpha_j (t_j-t'_j)$, where each $(t_j-t'_j)$ has a derivation in degree $d$ in BC and there are no cancelations.
\end{corollary}

\begin{proof}
By induction. At the beginning of the $\mathsf{PC}_>$ we have binomials. Then at each inference step apply Lemma \ref{lem:linComb}.
\end{proof}

\begin{theorem}\label{thm:BCtoPC<}
Given a $k$-XOR formula $\phi$. If the minimum degree to refute the binomial encoding of $\phi$ in Binomial Calculus (BC) is $D$, then the minimum degree to refute the polynomial encoding of $\phi$ in Positivstellensatz Calculus ($\mathsf{PC}_>$) is at least $D/2$.
\end{theorem}
\begin{proof}
Suppose by contradiction that there exists a proof of degree $d<D/2$ of the polynomial encoding $P$ of $\phi$ in $\mathsf{PC}_>$. That is we have an equation of the form 
\begin{equation}\label{eq:p'sum}
p'=1+\sum_j h_j^2,
\end{equation}
where $p'=0$ is inferred from $P$ according to the inference rules of $\mathsf{PC}_>$. By applying Corollary \ref{cor:normal-form} wlog we can suppose that $p'=\sum_i\alpha_i(t_i-t'_i)$, where each $(t_j-t_j')$ has a BC derivation in degree $d$ and there are no cancelations.

Observe that for each $j$ $\deg(h_j^2)\leq d$\footnote{
By contradiction suppose that for some $j$ $\deg(h_j^2)>d$, then the leading term of $h_j$ can't cancel out in the sum $\sum_j h_j^2$, hence it should appear also in $p'$. But this is not possible as all monomials in $p'$ have degree not greater than $d$.
}
, and not just $\deg(\sum_j h_j^2)\leq d$.


Let us consider the linear operator $L:\RR[Y]\rightarrow \RR$ defined as follows: $L(1)=1$ and for each monomial $m$
\begin{equation*}
L(m) := \begin{cases}
      \alpha & \text{ if $m-\alpha$ with $\alpha\in \RR$ has a BC proof from $P$ of degree $\leq d$,} \\
      0 & \text{ otherwise.}
   \end{cases}
\end{equation*}

If we look just at monomials (and polynomials) of degree at most $d$ this operator is well defined and moreover in that case $L(m)\in \{-1,0,1\}$. 
In fact otherwise we could build the following $BC$ refutation of $P$: start with a BC derivation of $m=a$, for some $a\in \RR\setminus\{-1,1\}$, of degree $d<D/2$.
 Then take squares: $m^2=a^2$, but as in the encoding $P$ of $\phi$ we have the equations $y_i^2=1$ for each variable $y_i\in Y$ then $m^2=1$. 
 Hence we would have derived $\alpha^2=1$, ie a BC refutation of $P$ of degree $2d< D$. That is not possible, as $D$ is the minimal degree needed to refute $P$ in BC.

In order to apply $L$ to equation (\ref{eq:p'sum}) we want to prove the followings:
\begin{enumerate}
\item if $t-t'$ has a BC derivation of degree at most $d$ from $P$ then $L(t-t')=0$;
\item for each polynomial $p\in \RR[Y]$ of degree at most $d/2$ $L(p^2)\geq 0$.
\end{enumerate}
Then, from equation (\ref{eq:p'sum}), it follows an immediate contradiction 
$$
0=L(p')=1+\sum_jL(h_j^2)\geq 1.
$$

Property 1 is obvious: consider $a m -a' m'=0$. If we can prove in BC that $m=\alpha$, we can always by transitivity do the same for $m'$. 

The rest of the proof is devoted to prove property 2: as $L(y^2m)=L(m)$ we can focus on $p\in \RR[Y]$ over multilinear monomials. Let $p=\sum_{S\subseteq [n]}\alpha_S y_S$, where $y_S:=\prod_{i\in S} y_i$. Then

\begin{equation}\label{eq:p^2sum}
L(p^2) =  \sum_{S,T} \alpha_S \alpha_T L( y_S y_T)=\sum_{S,T}\alpha_S \alpha_T L(y_{S \Delta T}).
\end{equation}

Define now an undirected graph $G=(V,E)$ with vertex set the $y_S$ with $S$ appearing in $p$ and $(y_S,y_T)\in E$ iff $L(y_{S\Delta T}) = \pm 1$. 
Then $L$ induce a natural labeling mapping $E$ into $\{-1,1\}$. 
Notice that for each $S\subseteq [n]$ $(y_S,y_S)$ is always in $E$ as $L(y_{S\Delta S})=L(1)=1$.

Moreover if BC derives $y_{S\Delta T} = \pm1$ and $y_{T\Delta U}=\pm 1$ in degree $d$ then using inference BC derives in degree $d$ $y_{S\Delta U} = \pm1$: every connected component of $G$ is a clique. 
Moreover each connected component of $G$ can be split into two vertex sets $A,B$ such that for each $I,J$ in the same vertex set $L(y_{I \Delta J})=1$ and for $I \in A$ $J\in B$ $L(y_{I \Delta J})=-1$.

To prove the last statement it is sufficient to prove that for each triangle the product of the values of the labeling of its edges is $1$. Let $\{y_S,y_T,y_U\}$ be the vertexes of a triangle in $G$, then
$$
L(y_{S\Delta T})L(y_{T\Delta U})L(y_{S\Delta U})=L(y_{\emptyset})=L(1)=1.
$$

We prove a stronger result than $L(p^2)\geq 0$: we prove that this is true wrt every connected component of $G$. More precisely let $\mathcal{S}$ be a sub-polinomial of the RHS of equation (\ref{eq:p^2sum}) giving rise in $G$ to a connected component and let $A$ and $B$ as above. We show that $\mathcal{S}\geq 0$. From this will follow immediately that $L(p^2)\geq 0$.

\begin{equation*}
\begin{split}
\mathcal{S}=
\sum_{I, J\in A} \alpha_I \alpha_J L(y_{I\Delta J})+ \sum_{I, J\in B} \alpha_I \alpha_J L(y_{I\Delta J}) +\sum_{I\in A, J \in B} 2\alpha_I \alpha_J L(y_{I\Delta J})=
\\
=\sum_{I, J\in A} \alpha_I\alpha_J + \sum_{I, J\in B} \alpha_I \alpha_J -\sum_{I\in A, J \in B} 2\alpha_I \alpha_J=
\\
=\left(\sum_{I\in A} \alpha_I\right)^2 + \left(\sum_{J\in B} \alpha_J\right)^2 -\sum_{I\in A, J \in B} 2\alpha_I \alpha_J=
\\
=\left(\sum_{I\in A} \alpha_I -\sum_{J\in B}\alpha_J\right)^2\geq 0.
\end{split}
\end{equation*}
\end{proof}


%\begin{definition}\label{def:kxor}
 %The k-XOR problem is defined as follows:\\ given that the matrix  $A \in \{0,1\}^{\Delta n \times n}$ such that $\sum_j a_{ij} = k$,\\ and that $b \in \{0,1\}^{\Delta n}, x \in \{0,1\}^n$, decide whether $Ax = b$ (mod 2) is SAT.
%\end{definition}

%\begin{definition}\label{def:maxkxor}
 %The MAX k-XOR problem is the problem of finding the maximum number of equations in the k-XOR problem in definition (\ref{def:kxor}) that can be satisfied by an assignment.
%\end{definition}






% ------------------------- EPILOGUE ------------------------------
\bibliography{soscourse}
\bibliographystyle{alpha}

\end{document} 


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
